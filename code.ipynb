{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers as T\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練データと予測データのチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the seed value to make the result reproducible\n",
    "seed=42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fillnan\n",
    "train['abstract'].fillna(value='0', inplace = True)\n",
    "test['abstract'].fillna(value='0', inplace = True)\n",
    "\n",
    "#title + abstract\n",
    "train[\"text\"] = train[\"title\"] + train[\"abstract\"]\n",
    "train = train.drop(['abstract', 'title'], axis=1)\n",
    "test[\"text\"] = test[\"title\"] + test[\"abstract\"]\n",
    "test = test.drop(['abstract', 'title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 阈值のチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "border = len(train[train[\"judgement\"] == 1]) / len(train[\"judgement\"])\n",
    "print(border)\n",
    "border = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練と予測"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = 5\n",
    "Fold = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=seed)\n",
    "\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"judgement\"])):\n",
    "    train.loc[val_index, \"fold\"] = int(n)\n",
    "    \n",
    "train[\"fold\"] = train[\"fold\"].astype(np.uint8)\n",
    "    \n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, data, model_name, include_labels=True):\n",
    "        tokenizer = T.BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        self.data = data\n",
    "        self.include_labels = include_labels\n",
    "        self.text = data[\"text\"].tolist()\n",
    "        \n",
    "        self.encoded = tokenizer.batch_encode_plus(\n",
    "            self.text,\n",
    "            padding = 'max_length',            \n",
    "            max_length = 512,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True)\n",
    "        if self.include_labels:\n",
    "            self.labels = data[\"judgement\"].values\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = torch.tensor(self.encoded['input_ids'][idx])\n",
    "        attention_mask = torch.tensor(self.encoded['attention_mask'][idx])        \n",
    "        if self.include_labels:\n",
    "            label = torch.tensor(self.labels[idx]).float()\n",
    "            return input_ids, attention_mask, label\n",
    "        return input_ids, attention_mask\n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.model = T.BertForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        out = self.sigmoid(out.logits).squeeze()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(train, fold,trainepoch,batchsize):\n",
    "\n",
    "    print(f\"========== fold: {fold} training ==========\")\n",
    "       \n",
    "    # ====================================================\n",
    "    # Data Loader\n",
    "    # ===================================================\n",
    "    trn_idx = train[train[\"fold\"] != fold].index\n",
    "    val_idx = train[train[\"fold\"] == fold].index\n",
    "    \n",
    "    train_folds = train.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = train.loc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = BaseDataset(train_folds, \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    valid_dataset = BaseDataset(valid_folds, \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batchsize,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batchsize,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "       \n",
    "    # ====================================================\n",
    "    # Model\n",
    "    # ====================================================\n",
    "    model = BaseModel(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = T.AdamW(model.parameters(),\n",
    "                        lr=2e-5,)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # ====================================================\n",
    "    # Loop\n",
    "    # ====================================================\n",
    "    best_score = -1\n",
    "    for epoch in range(trainepoch):       \n",
    "        #train\n",
    "        model.train()\n",
    "        for step, (input_ids, attention_mask, labels) in enumerate(train_loader):           \n",
    "            optimizer.zero_grad()     \n",
    "            #to device\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)           \n",
    "            batch_size = labels.size(0)\n",
    "            # compute loss\n",
    "            y_preds = model(input_ids, attention_mask)           \n",
    "            loss = criterion(y_preds, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()           \n",
    "                        \n",
    "        # eval\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        for step, (input_ids, attention_mask, labels) in enumerate(valid_loader):\n",
    "            #to device\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "            batch_size = labels.size(0)\n",
    "            # compute loss\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(input_ids, attention_mask)\n",
    "            loss = criterion(y_preds, labels)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())            \n",
    "        \n",
    "        preds = np.concatenate(preds)\n",
    "        valid_labels = valid_folds[\"judgement\"].values\n",
    "        score = fbeta_score(valid_labels, np.where(preds < border, 0, 1), beta=7.0)\n",
    "        print(f\"Epoch {epoch+1} -Score: {score:.4f}\")    \n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            torch.save({\"model\": model.state_dict(), \"preds\": preds}, f\"./PubMedBERT_base_uncased_fold{fold}_best.pth\")          \n",
    "    print(f\"Best Score: {best_score:.4f}\")\n",
    "\n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(batchsize): \n",
    "    predictions = []\n",
    "    test_dataset = BaseDataset(test, \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\", include_labels=False)   \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batchsize,\n",
    "        shuffle=False,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    for fold in range(k_fold):\n",
    "        print(f\"==========fold: {fold} predict ==========\")\n",
    "        model = BaseModel(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\")\n",
    "        model.to(device) \n",
    "        \n",
    "        #load best parameters\n",
    "        model.load_state_dict(torch.load(f\"./PubMedBERT_base_uncased_fold{fold}_best.pth\")[\"model\"])            \n",
    "        model.eval()\n",
    "        preds = []\n",
    "    \n",
    "        for i, (input_ids, attention_mask) in enumerate(test_loader):\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(input_ids, attention_mask)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())\n",
    "            \n",
    "        preds = np.concatenate(preds)\n",
    "        predictions.append(preds)\n",
    "        \n",
    "    predictions = np.mean(predictions, axis=0)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 3\n",
    "trainepoch = 10\n",
    "\n",
    "scores = []\n",
    "for fold in range(k_fold):\n",
    "    score = train_loop(train, fold,trainepoch,batchsize)\n",
    "    scores.append(score)\n",
    "print(f\"========== CV ==========\")\n",
    "print(f\"SCORE: {float(sum(scores)/len(scores)):<.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 3\n",
    "predictions = predict(batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 半教師あり学習を使う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 疑似ラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.where(predictions < border, 0, 1)\n",
    "sub = pd.read_csv(\"./data/sample_submit.csv\", header=None)\n",
    "sub.columns = [\"id\",\"judgement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(columns=(\"id\", \"judgement\", \"text\",))\n",
    "df2[\"id\"] = sub[\"id\"]\n",
    "df2[\"judgement\"] = preds\n",
    "df2[\"text\"] = test[\"text\"]\n",
    "\n",
    "df2[\"fold\"] = \"000\"\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"judgement\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練データの\"fold\"値をランダムで更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = 5\n",
    "Fold = StratifiedKFold(n_splits=k_fold, shuffle=True, random_state=seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"judgement\"])):\n",
    "    train.loc[val_index, \"fold\"] = int(n)\n",
    "train[\"fold\"] = train[\"fold\"].astype(np.uint8)\n",
    "    \n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 疑似ラベル付きテストデータを訓練データと混合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,df2])\n",
    "train = train.reset_index(drop=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 3\n",
    "trainepoch = 10\n",
    "\n",
    "scores = []\n",
    "for fold in range(k_fold):\n",
    "    score = train_loop(train,fold,trainepoch,batchsize)\n",
    "    scores.append(score)\n",
    "print(f\"========== CV ==========\")\n",
    "print(f\"SCORE: {float(sum(scores)/len(scores)):<.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 3\n",
    "predictions = predict(batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.where(predictions < border, 0, 1)\n",
    "sub = pd.read_csv(\"./data/sample_submit.csv\", header=None)\n",
    "sub.columns = [\"id\", \"judgement\"]\n",
    "sub[\"judgement\"] = preds\n",
    "sub.to_csv(\"./submission.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
